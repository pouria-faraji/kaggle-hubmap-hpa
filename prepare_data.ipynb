{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHGz-l2Ma8zx"
      },
      "source": [
        "### Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlZNGV12qMuq"
      },
      "source": [
        "#### Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "511yBsg4lASk",
        "outputId": "934283fc-76e3-4c4c-bfee-15b6610d850e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading hubmap-organ-segmentation.zip to /content\n",
            "100% 5.76G/5.78G [00:25<00:00, 249MB/s]\n",
            "100% 5.78G/5.78G [00:25<00:00, 239MB/s]\n"
          ]
        }
      ],
      "source": [
        "! pip install -q kaggle\n",
        "! mkdir -p ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c hubmap-organ-segmentation\n",
        "! mkdir -p dataset\n",
        "! unzip -q hubmap-organ-segmentation.zip -d dataset\n",
        "! rm -rf hubmap-organ-segmentation.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLkGSMo9qTt7"
      },
      "source": [
        "#### Install and Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89cKbu6Il_I7",
        "outputId": "9a89069f-400f-4f2d-bb5d-9afcc346430b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▋                          | 10 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 20 kB 27.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 30 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 40 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 51 kB 32.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 58 kB 3.8 MB/s \n",
            "\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting segmentation-models\n",
            "  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
            "Collecting image-classifiers==1.0.0\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting efficientnet==1.0.0\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.18.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.5.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2021.11.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.7.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.9.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.6.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (7.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.15.0)\n",
            "Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n"
          ]
        }
      ],
      "source": [
        "! pip install -q patchify\n",
        "! pip install -q segmentation-models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUlFp_yEn_KS",
        "outputId": "9a037a8e-208d-46ec-d5fd-de10e61eedc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Segmentation Models: using `keras` framework.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import pathlib\n",
        "import warnings\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np  # linear algebra\n",
        "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import patchify\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from matplotlib import animation\n",
        "from PIL import Image\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tqdm import tqdm\n",
        "\n",
        "from Manager import InputMode, Manager\n",
        "from Augment import Augment\n",
        "from DiceLoss import DiceLoss\n",
        "from DiceMetric import DiceCoefficient\n",
        "from UNet import UNet\n",
        "\n",
        "# import segmentation_models as sm\n",
        "\n",
        "# from segmentation_models.losses import DiceLoss\n",
        "# from segmentation_models.metrics import IOUScore\n",
        "\n",
        "# sm.set_framework('tf.keras')\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = 'false'\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = 'false'\n",
        "os.environ['TF_DISABLE_SEGMENT_REDUCTION_OP_DETERMINISM_EXCEPTIONS'] = 'true'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO46m1hPqbqv"
      },
      "source": [
        "#### Create Image Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pjtc_T0oopkM"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('dataset/train.csv')\n",
        "# sort train_df by id and reset index\n",
        "train_df = train_df.sort_values('id')\n",
        "train_df = train_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlVfKPQjo7w2",
        "outputId": "ede6d95b-a448-49ed-f63a-2716418ad8e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 351/351 [00:39<00:00,  8.97it/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p dataset/train_masks\n",
        "\n",
        "def rle2mask(mask_rle, shape=(1600,256)):\n",
        "    '''\n",
        "    mask_rle: run-length as string formated (start length)\n",
        "    shape: (width,height) of array to return \n",
        "    Returns numpy array, 1 - mask, 0 - background\n",
        "\n",
        "    '''\n",
        "    s = mask_rle.split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "    starts -= 1\n",
        "    ends = starts + lengths\n",
        "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1 * 255\n",
        "    return img.reshape(shape).T\n",
        "\n",
        "for id in tqdm(train_df['id']):\n",
        "    rle = train_df[train_df['id'] == id]['rle'].values[0]\n",
        "    width = train_df[train_df['id'] == id]['img_width'].values[0]\n",
        "    height = train_df[train_df['id'] == id]['img_height'].values[0]\n",
        "\n",
        "    mask = rle2mask(rle, (height, width))\n",
        "    cv2.imwrite(f'dataset/train_masks/{id}.png', mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nqRACHkqhrL"
      },
      "source": [
        "#### Patchify Images and Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tW0x6qMWos9G"
      },
      "outputs": [],
      "source": [
        "def get_correct_dimension(number, divisible):\n",
        "    if number % divisible == 0:\n",
        "        return number\n",
        "    else:\n",
        "        return number + divisible - (number % divisible)\n",
        "\n",
        "def correct_image_size(img, size):\n",
        "    if img.shape[0] != size:\n",
        "        img = cv2.resize(img, (size, size))\n",
        "    return img\n",
        "\n",
        "def display_overlay(image, mask):\n",
        "    plt.figure(figsize = (7,7))\n",
        "    plt.imshow(image)\n",
        "    plt.imshow(mask, alpha=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K--sSpqToucz"
      },
      "outputs": [],
      "source": [
        "train_masks_dir = 'dataset/train_masks'\n",
        "train_masks = [name for name in os.listdir(train_masks_dir)]\n",
        "train_masks = sorted(train_masks, key=lambda x: int(x.split('.')[0]))\n",
        "\n",
        "train_images_dir = 'dataset/train_images'\n",
        "train_images = [name for name in os.listdir(train_images_dir)]\n",
        "train_images = sorted(train_images, key=lambda x: int(x.split('.')[0]))\n",
        "\n",
        "assert len(train_masks) == train_df.shape[0]\n",
        "assert len(train_images) == len(train_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8Gf81D7pL-B",
        "outputId": "68a1f322-a116-4e6c-c018-2eb029b108fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Images\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 221/221 [02:31<00:00,  1.46it/s]\n",
            "100%|██████████| 65/65 [00:47<00:00,  1.37it/s]\n",
            "100%|██████████| 65/65 [00:46<00:00,  1.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Masks\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 221/221 [05:54<00:00,  1.60s/it]\n",
            "100%|██████████| 65/65 [00:05<00:00, 12.29it/s]\n",
            "100%|██████████| 65/65 [00:05<00:00, 12.52it/s]\n"
          ]
        }
      ],
      "source": [
        "# Equal number of elements in each sub-list\n",
        "def subdivide_list(the_list, n_elems):\n",
        "    return [the_list[i:i+n_elems] for i in range(0,len(the_list), n_elems)]\n",
        "\n",
        "# Different number of elements for validation and test sub-list\n",
        "def subdivide_list_2(the_list, test_size):\n",
        "    train_list_size = len(the_list) - (2*test_size)\n",
        "    train_list = [the_list[i:i+train_list_size] for i in range(0, train_list_size, train_list_size)]\n",
        "    val_list = [the_list[i:i+test_size] for i in range(train_list_size, train_list_size+test_size,train_list_size+test_size )]\n",
        "    test_list = [the_list[i:i+test_size] for i in range(train_list_size+test_size, train_list_size+test_size+test_size, train_list_size+test_size+test_size)]\n",
        "    return train_list + val_list + test_list\n",
        "\n",
        "PATCH_SIZE = 1024\n",
        "NUMBER_OF_MEMBERS = 117\n",
        "TEST_SIZE = 65\n",
        "\n",
        "train_images = subdivide_list_2(train_images, TEST_SIZE)\n",
        "train_masks = subdivide_list_2(train_masks, TEST_SIZE)\n",
        "\n",
        "print(\"Train Images\")\n",
        "for index, value in enumerate(train_images):\n",
        "    group_path = r'dataset/train_images_' + str(PATCH_SIZE) + '_' + str(index)\n",
        "    if not os.path.exists(group_path):\n",
        "        os.makedirs(group_path)\n",
        "\n",
        "    for train_image_filename in tqdm(value):\n",
        "        image_id = int(train_image_filename.split('.')[0])\n",
        "        train_image_file = train_images_dir + '/' + train_image_filename\n",
        "        image = cv2.imread(train_image_file)\n",
        "        image = correct_image_size(image, get_correct_dimension(image.shape[0], PATCH_SIZE))\n",
        "\n",
        "        patched_image = patchify.patchify(image, (PATCH_SIZE, PATCH_SIZE, 3), step=PATCH_SIZE)\n",
        "        for i in range(patched_image.shape[0]):\n",
        "            for j in range(patched_image.shape[1]):\n",
        "                cv2.imwrite(group_path + f'/{image_id}_{i}_{j}.png', patched_image[i, j, 0, :, :, :])\n",
        "\n",
        "print(\"Train Masks\")\n",
        "for index, value in enumerate(train_masks):\n",
        "    group_path = r'dataset/train_masks_' + str(PATCH_SIZE) + '_' + str(index)\n",
        "    if not os.path.exists(group_path):\n",
        "        os.makedirs(group_path)\n",
        "\n",
        "    for train_mask_filename in tqdm(value):\n",
        "        image_id = int(train_mask_filename.split('.')[0])\n",
        "        train_mask_file = train_masks_dir + '/' + train_mask_filename\n",
        "        image = cv2.imread(train_mask_file, cv2.IMREAD_GRAYSCALE)\n",
        "        image = correct_image_size(image, get_correct_dimension(image.shape[0], PATCH_SIZE))\n",
        "\n",
        "        patched_mask = patchify.patchify(image, (PATCH_SIZE, PATCH_SIZE), step=PATCH_SIZE)\n",
        "        for i in range(patched_mask.shape[0]):\n",
        "            for j in range(patched_mask.shape[1]):\n",
        "                mask = patched_mask[i, j, :, :]\n",
        "                mask_location = group_path + f'/{image_id}_{i}_{j}.png'\n",
        "                cv2.imwrite(mask_location, mask)\n",
        "\n",
        "                if index < 1 :\n",
        "                    # Adding augmented duplicate images and masks for non black masks\n",
        "                    mask = mask / 255.0\n",
        "                    n_pixels = mask.shape[0] * mask.shape[1]\n",
        "                    n_white_pixels = mask.sum()\n",
        "                    white_ratio = n_white_pixels/n_pixels\n",
        "                    if white_ratio >= 0.05:\n",
        "                        mask = mask * 255.0\n",
        "                        corresponding_image_file = 'dataset/train_images_' + str(PATCH_SIZE) + '_' + str(index) + f'/{image_id}_{i}_{j}.png'\n",
        "                        corresponding_image = cv2.imread(corresponding_image_file)\n",
        "\n",
        "                        augment = Augment(seed=random.randint(0,1000))\n",
        "\n",
        "                        mask = np.expand_dims(mask, 2)\n",
        "\n",
        "                        augmented_image, augmented_mask = augment(corresponding_image, mask)\n",
        "\n",
        "                        cv2.imwrite(corresponding_image_file.replace('.png', '_copy_1.png'), augmented_image.numpy())\n",
        "                        cv2.imwrite(mask_location.replace('.png', '_copy_1.png'), augmented_mask.numpy())\n",
        "\n",
        "                        augment = Augment(seed=random.randint(0,1000))\n",
        "                        augmented_image, augmented_mask = augment(corresponding_image, mask)\n",
        "\n",
        "                        cv2.imwrite(corresponding_image_file.replace('.png', '_copy_2.png'), augmented_image.numpy())\n",
        "                        cv2.imwrite(mask_location.replace('.png', '_copy_2.png'), augmented_mask.numpy())\n",
        "\n",
        "                        augment = Augment(seed=random.randint(0,1000))\n",
        "                        augmented_image, augmented_mask = augment(corresponding_image, mask)\n",
        "\n",
        "                        cv2.imwrite(corresponding_image_file.replace('.png', '_copy_3.png'), augmented_image.numpy())\n",
        "                        cv2.imwrite(mask_location.replace('.png', '_copy_3.png'), augmented_mask.numpy())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "sHGz-l2Ma8zx",
        "SlZNGV12qMuq",
        "kO46m1hPqbqv",
        "TaU94Nt_eqLs"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
